{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec78a642-a034-4450-a800-f97e2675f237",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "- This notebook is a beginner's guide to all the steps involved in text-preprocessing.  \n",
    "- All steps involved in converting unstructured data to structured.  \n",
    "- Source of tutorial: [FreeCodeCamp](https://www.freecodecamp.org/news/natural-language-processing-techniques-for-beginners/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603568ff-ed0f-4812-a2d9-0521c6389f33",
   "metadata": {},
   "source": [
    "### Pre-processing stages:\n",
    "1. Tokenization\n",
    "2. Normalization\n",
    "3. Lemmetization\n",
    "4. Stemming\n",
    "5. ...\n",
    "6. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e2b6f0-94f0-4017-8772-c85755356b0d",
   "metadata": {},
   "source": [
    "#### 1. Tokenization  \n",
    "\n",
    "i) **Word Tokenization-** each word is a token. the sentences are broken down into single words.  \n",
    "ii) **Sentence Tokenization-** phrases are a token. sentences are broken down into words and phrases.\n",
    "\n",
    "##### Some tokenization algorithms\n",
    "1. whitespace tokenization\n",
    "2. regular expression tokenization\n",
    "3. statistical tokenization etc.\n",
    "\n",
    "Type of algorithm used depends on the task at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b833bf2-2009-4d0e-9dfc-59b1e678ae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'For the powerful, crimes are those that others commit.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a3a17d0-299c-429b-9355-7d586b674709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['For', 'the', 'powerful,', 'crimes', 'are', 'those', 'that', 'others', 'commit.']\n"
     ]
    }
   ],
   "source": [
    "words = text.split()\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a8aa03-9fee-441f-a51f-4430fdbaf9f4",
   "metadata": {},
   "source": [
    "#### 2. Normalization\n",
    "\n",
    "makes text consistent.\n",
    "\n",
    "- convert all to lowercase.\n",
    "- remove numbers & punctuation marks.\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "862aabf5-fbad-4fc8-b8a1-b73218d5beee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to the moon and back.\n"
     ]
    }
   ],
   "source": [
    "text2 = 'To THe mooN and bAcK.'\n",
    "text2_lower = text2.lower()\n",
    "print(text2_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85772a01-2773-4e30-b886-ede774c27f67",
   "metadata": {},
   "source": [
    "#### 3. Stemming\n",
    "\n",
    "Reduce the words to their root form.  \n",
    "For e.g.- ***\"study, studying, studied\"*** all get converted to ***\"study\".***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ccf2b4-6cea-4747-a49a-006b4f52ca6e",
   "metadata": {},
   "source": [
    "#### 4. Lemmatisation\n",
    "\n",
    "Better than stemming.  \n",
    "It takes into consideration the \"part of speech\" whether word is mentioned as a noun or verb.  \n",
    "Before converting a word to base form, it takes into account structure of the word.  \n",
    "It is more computationally expensive as it is more accurate than stemming."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
